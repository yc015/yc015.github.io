# > name: Name of your project
# > descr: Description of your project
# > demo: Link to your project
# > tags: List of technologies you used in your projects
#
# Example of a project
# - name: project X
#   descr: "Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam"
#   demo: https://example.com/
#   tags:
#     - tag: MongoDB
#     - tag: Express
#     - tag: AngularJS
#     - tag: Node

- name: "ChatGPT Doesn't Trust Chargers Fans: Guardrail Sensitivity in Context"
  descr: "Not all users are turned away by chatbots for making suspicious requests. Your identity plays a key role when chatbot decides whether to refuse your potentially problematic inquiry. <br><br>Our new study shows that the ChatGPT guardrails sensitive knowledge to users with different gender, racial, and political demographics. In particular, younger, female, and Asian-American users are more likely to trigger the refusal from the ChatGPT when querying sensitive information. We proposed a new evaluation framework to identify such bias in the chatbot's refusal behaviors. <br> <br> <img src='assets/img/guardrail-sensitivity-experimental-setup.png' alt='guardrail sensitivity' style='width:-webkit-fill-available; height: -webkit-fill-available;'> <br> <a class='highlight-link' href='https://aclanthology.org/2024.emnlp-main.363/' target='_blank' rel='noreferrer'> Paper </a>"
  demo: https://aclanthology.org/2024.emnlp-main.363/
  tags:
    - tag: EMNLP 2024 Main
    - tag: Chatbot
    - tag: Human-AI Interaction
    - tag: Bias

- name: Designing a Dashboard for Transparency and Control of Conversational AI
  descr: "Have you ever thought about if chatbot LLMs are internally modeling your profile? If they are, how might this model of you influence the answers they give to your questions? <br> <br> Our experiments provide evidence that a conversational AI is internally profling its user during the chat. We design an end-to-end prototype—TalkTuner—that expose this internal user model to the users. User study shows this new chatbot UI design impacts the user's trust in AIs and expose biases of LLM systems. <br> <br> <img src='assets/img/dashboard_overview.png' alt='dashboard-overview' style='width:-webkit-fill-available;height: -webkit-fill-available;'> <br> <a class='highlight-link' href='https://arxiv.org/abs/2406.07882' target='_blank' rel='noreferrer'> Paper Preprint </a>"
  demo: https://yc015.github.io/TalkTuner-a-dashboard-ui-for-chatbot-llm/
  tags:
    - tag: preprint
    - tag: Chatbot
    - tag: NLP
    - tag: Interpretability

- name: Do Language Models Learn Causal Representations of Space?
  descr: "Recent work from <a class='highlight-link' href='https://arxiv.org/abs/2310.02207' target='_blank' rel='noreferrer'>Gurnee et al.</a> show that the activations of neural language models have high correlation with the spatial and temporal properties of their inputs. However, the work didn't estabilish a causal link between two. Our experiments, filling a part of this blank, show that editing LLM's spatial representations can improve the model's performance on a simple spatial task.<br> <br> <img src='assets/paper/gpt_logit_change.png' alt='language_logit_change' style='width:-webkit-fill-available;height: -webkit-fill-available;'> <br> <a class='highlight-link' href='https://arxiv.org/abs/2312.16257' target='_blank' rel='noreferrer'> Paper Preprint </a>"
  demo: https://github.com/jenniferz99/causal-spatial-representations
  tags:
    - tag: preprint
    - tag: NLP
    - tag: Interpretability

- name: Probe & Control the 3D Representations in Diffusion Model
  descr: "Does the 2D image generative model has an internal model of 3D geometry? Can a 2D neural network see beyond the X-Y dimension of a matrix of pixels? Our project found controllable representations of 3D geometry inside diffusion model. <br> <br> <img src='assets/img/southern_container_plants.gif' alt='diffusion_model' style='width:-webkit-fill-available;height: -webkit-fill-available'> <br> <a class='highlight-link' href='https://arxiv.org/abs/2306.05720.pdf' target='_blank' rel='noreferrer'> Paper </a><br><br><a class='highlight-link' href='https://www.youtube.com/watch?v=YytxbKigcXA' target='_blank' rel='noreferrer'> Youtube Video</a> (55K Views)"
  demo: https://yc015.github.io/scene-representation-diffusion-model/
  tags:
    - tag: NeurIPS 2023
    - tag: CV
    - tag: Interpretability

- name: Visualize Attention Flow inside Large Transformer Models
  descr: "Wonder how attention flows inside your Vision Transformer? What visual patterns are recognize by machine's attention? Does machine's attention resemble human's visual cognition? Collaboration with Catherine Yeh. My main contribution is the visualization of learnt attention in vision transformer models. <br> <br> <img src='assets/img/attn_viz.gif' alt='attention_viz' style='width:-webkit-fill-available;height: -webkit-fill-available;'> <br> <a class='highlight-link' href='https://arxiv.org/abs/2305.03210' target='_blank' rel='noreferrer'> Paper</a>"
  demo: http://attentionviz.com/
  tags:
    - tag: IEEE VIS 2023
    - tag: Visualization
    - tag: Interpretability

- name: "KALMUS: tools for color analysis of films"
  descr: "KALMUS is a Python package for the computational analysis of colors in films. It provides quantitative tools to study and compare the use of film color. This package serves two purposes: (1) various ways to measure, calculate and compare a film’s colors and (2) various ways to visualize a film’s color. <br> <br> <img src='assets/img/mission_barcode_Foreground_avg.png' alt='kalmus_img' height='100vh' style='max-width: -webkit-fill-available;'> <img src='assets/img/kalmus_color_t.png' alt='kalmus_img' height='100vh' style='max-width: -webkit-fill-available;'><br><img src='assets/img/kalmus_gui.png' alt='kalmus_img' style='width:-webkit-fill-available;height: -webkit-fill-available;'>"
  demo: https://github.com/KALMUS-Color-Toolkit/KALMUS
  tags:
    - tag: JOSS 2021
    - tag: Visualization
    - tag: Digital Humanities

- name: Fully Automated Full-Video Multi-heartbeat Echocardiography Segmentation
  descr: "We aim to further improve the accuracy and clinical applicability of echocardiography video segmentation by extending the analysis from half-heartbeat (End-diastolic to End-systolic phases) to multi-heartbeat video. We proposed a sliding window data augmentation technique for efficiently learning moition tracking and semantic segmentation from sparesely annotated echo videos (only 2 annotations per video). 
  
  <a class='highlight-link' href='https://spie.org/medical-imaging/presentation/Fully-automated-multi-heartbeat-echocardiography-video-segmentation-and-motion-tracking/12032-29' target='_blank' rel='noreferrer'> Paper </a>. <br> <br> <img src='assets/img/Full_Video_Segmentation_with_Volume_Trend.gif' alt='fully_automated_video_segmentation' height='240vh'>"
  demo: http://eg.bucknell.edu/~jvs008/research/cardiac/SPIE22/chenSPIE22_preprint.pdf
  tags:
    - tag: SPIE Medical Imaging 2022
    - tag: CV
    - tag: Medical Imaging


- name: Joint Motion Tracking and Video Segmentation of Echocardiography
  descr: "We assessed a 3D-UNet's performance on jointly segmenting sparsely annotated half-heartbeat echocardiography videos and estimating cardiac structure's motions. The 3D-UNet was trained on CAMUS dataset, and we evaluated its generalizability on Stanford's EchoNet dataset. Comparing with traditional frame-based segmentation method, our results show that the joint learning of motion tracking and segmentation enhances the segmentation performance on video data. The video model also has better generalizability on unseen dataset than frame-based model. <br> <br> <img src='assets/img/4CH_Segmentation.gif' alt='4ch_video_segmentation' height='200vh'>"
  demo: http://eg.bucknell.edu/~jvs008/research/cardiac/SPIE21/chenSPIE21_preprint.pdf
  tags:
    - tag: SPIE Medical Imaging 2021
    - tag: CV
    - tag: Medical Imaging


# - name: "Stochastic method for optimizing stock trading strategy"
#   descr: "This project implements and extends a stochastic approximation (SA) method proposed by Song et al. [1]. This SA method aims to find an optimal set of buying and selling thresholds for trading a stock. It assumes the stock has a mean-reversion property so the stock price will oscillate around a long-term average. <br> <br> [1] Q. S. Song, G. Yin, and Q. Zhang, “Numerical methods for buying-low-and-selling-high stock policy,” 2008 American Control Conference, 2008, <a class='highlight-link' href='https://doi.org/10.1109/ACC.2008.4586627' target='_blank' rel='noreferrer'> https://doi.org/10.1109/ACC.2008.4586627 </a> <br> <br> <img src='assets/img/local_stochastic_optimization_stock_trading.png' alt='stochastic_optimization' height='180vh'>"
#   demo: https://github.com/yc015/stochastic-optimization-of-stock-buying-selling
#   tags:
#     - tag: Project
#     - tag: Stock trading
#     - tag: Optimization

# - name: "R Visualizations: Data, Arts, COVID, and Cardiology"
#   descr: "Portfolio Website for Math 230: Data Visualization <br> This website hosts the visualization and generative artworks that I created during the course. <br> <br> The project is implemented in <a class='highlight-link' href='https://www.r-project.org/' target='_blank' rel='noreferrer'>R</a>, and the portfolio website is built with <a class='highlight-link' href='https://github.com/rstudio/distill' target='_blank' rel='noreferrer'>Distill</a>. <br> <br> <img src='assets/img/covid_heatmap_cumulative_cases.gif' alt='covid_heatmap' height='180vh'> <img src='assets/img/function_art.png' alt='r_visualization_artwork' height='180vh'>"
#   demo: https://yc015.github.io/yida-r-visualization-portfolio-website/
#   tags:
#     - tag: Porject
#     - tag: Visualization
#     - tag: Generative Art
